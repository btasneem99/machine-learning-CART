---
title: "SDS/CSC 293 Mini-Project 4: CART"
author: "Group 04: Willow Crawford-Crudell & Bushra Tasneem"
date: "Wednesday, April 17^th^, 2019"
output:
  html_document:
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: kable
---

```{r setup, include=FALSE}
# Load all your packages here:
library(tidyverse)
library(GGally)
library(rpart)
library(yardstick)


# Set default behavior for all code chunks here:
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 16/2, fig.height = 9/2
)

# Set seed value of random number generator here. This is in order to get
# "replicable" randomness, so that any results based on random sampling or
# resampling are replicable everytime you knit this file. Why use a seed value
# of 76? For no other reason than 76 is one of my favorite numbers:
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(76)
```

You will be fitting CART models to the data from the [Ghouls, Goblins, and Ghosts... Boo!](https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo/){target="_blank"} Kaggle competition. The competition's score for leaderboard purposes is the "Categorization Accuracy". However you will **NOT** be making any submissions to Kaggle.



***



# Load data

Read in data provided by Kaggle for this competition. They are organized in the `data/` folder of this RStudio project:

```{r}
training <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sample_submission.csv")
```

***

# Minimally viable product

Perform the following exploratory data analyses:

## Univariate explorations

**Categorical predictor**: Create a visualization of the categorical predictor variable `color`.

```{r}
ggplot(training, aes(x = color)) +
  geom_bar() +
  labs(x = "Color", title = "Distribution of categorical predictor variable")
```


**Outcome variable**: Create a visualization of the categorical predictor variable `type`.

```{r}
ggplot(training, aes(x = type)) +
  geom_bar() +
  labs(x = "Monster Type", title = "Distribution of categorical outcome variable")
```


## Mutlivariate explorations

**Numerical predictors**: Create a visualization of the relationship of all four numerical predictor variables at once (`bone_length`, `rotting_flesh`, `hair_length`, `has_soul`) using the `ggpairs()` function from the `GGally` [package](http://ggobi.github.io/ggally/#ggallyggpairs). 

```{r}
am <- ggpairs(training, columns = c("bone_length", "rotting_flesh", "hair_length", "has_soul"), columnLabels = c("Bone Length", "Rotting Flesh", "Hair Length", "Has Soul"))
am
```

**Relationship of categorical predictor and outcome variable**: Create a visualization of the relationship between the categorical outcome variable `type` and any predictor varible of your choosing.


```{r}
ggplot(training, aes(x = color, fill = as.factor(type))) +
  geom_bar(position = "fill") +
  labs(fill = "type", title = "Distribution of monsters by color")
```

***

# Due diligence

1. Fit a CART where:
    * You use only the numerical predictors.
    * The maximum depth of the tree is 5.
    * You use the default "complexity parameter" 
1. Plot the tree.
1. Make predictions `type_hat` on the `training` data. Hint compare the output of `predict(model_CART, type = "prob")` and `predict(model_CART, type = "class")`.

1. Compute the "classification accuracy".

```{r, fig.height = 9, fig.width=12}

model_formula <- as.formula(type ~ has_soul+hair_length+bone_length+rotting_flesh)
tree_parameters <- rpart.control(maxdepth = 5)
model_CART <- rpart(model_formula, data = training, control = tree_parameters)

# Plot CART model
plot(model_CART, margin=0.5)
text(model_CART, use.n = TRUE)
title("Predicting monster type using all numerical predictor variables")
box()
```

```{r}
class_hat_train <- model_CART %>%
  predict(type = "class", newdata = training) %>%
  # Convert matrix object to data frame:
  as_tibble()
```

```{r}
#Calculate the accuracy of the model on training data
mean(training$type == class_hat_train$value)
```


***



# Reaching for the stars

Note that the $\alpha$ complexity parameter is the `cp` argument to `rpart.control()`.

1. Reusing the MP1 solutions code, for the range of `alpha` complexity parameters in the `alpha_df` data frame, return an estimate of the accuracy/error that Kaggle would return.
1. Plot the relationship between the alpha complexity parameter and accuracy.
1. Using the optimal $\alpha^*$ complexity parameter, write a `submission.csv` suitable for submission to Kaggle.

# Use cross validation to evaluate the complexity parameter
```{r}
alpha_df <- tibble(
  alpha = seq(from = 0, to = 0.1, length = 250),
  accuracy = 0
)
```



```{r}
set.seed(76)
training <- training %>% 
  sample_frac(1) %>% 
  mutate(fold = rep(1:5, length = n())) %>% 
  arrange(fold)
  accuracy_vector <- rep(0, 5)

for(i in 1:nrow(alpha_df)){
  alpha <- alpha_df$alpha[i]

  for(j in 1:5){
    pretend_training <- training %>% 
      filter(fold != j)
    pretend_test <- training %>% 
      filter(fold == j)
    
    # Fit model on pretend training
    model_formula <- as.formula(type ~ has_soul+hair_length+bone_length+rotting_flesh)
    tree_parameters <- rpart.control(maxdepth = 5, cp = alpha)
    model_CART <- rpart(model_formula, data = pretend_training, control = tree_parameters)


    # Make predictions
     class_hat_prentend_test <- model_CART %>%
      predict(type = "class", newdata = pretend_test) %>%
      # Convert matrix object to data frame:
      as.tibble()
  
  value <- mean(pretend_test$type == class_hat_prentend_test$value)
  
  #accuracy_vector[j] <- value$.estimate
  accuracy_vector[j] <- value
  }
  alpha_df$accuracy[i] <- mean(accuracy_vector) 
}
```

# Plot the relationship between the complexity parameter and accuracy

```{r}
ggplot(data = alpha_df, aes(x = alpha, y = accuracy)) + geom_line() + 
  labs(x = "`alpha`, the complexity parameter", 
       y = "Accuracy", title = "Plot evaluating the tradeoff between overfitting and complexity")

```



```{r}
alpha_means <- alpha_df %>%
 group_by(accuracy)%>%
 summarize(Mean_alpha = mean(alpha))

 alpha_star <- alpha_means[which.max(alpha_means$accuracy),]$Mean_alpha
 estimated_accuracy <- alpha_means[which.max(alpha_means$accuracy),]$accuracy
 alpha_star
 estimated_accuracy
```

The estimated accuracy of our model using $\alpha^* = 0.007630522$ is 0.6923604. 

# Make predictions on the test data and submit results to Kaggle.com

```{r}
model_formula <- as.formula(type ~ has_soul+hair_length+bone_length+rotting_flesh)
tree_parameters <- rpart.control(maxdepth = 5, cp = alpha_star)
model_CART <- rpart(model_formula, data = training, control = tree_parameters)

class_hat_test <- model_CART %>%
  predict(type = "class", newdata = test) %>%
  as_tibble()
```

```{r}
submission <- sample_submission %>% 
  mutate(type = class_hat_test$value)

write_csv(submission, path = "data/submission_due_diligence.csv")
```

***

# Point of diminishing returns

* Use one-hot-enconding to fit a predictive CART model using the categorical variable `color` and plot the tree. Set the maximum depth of the tree to 5 and use the default "complexity parameter".
* No need to generate an estimate of the accuracy that Kaggle would return. 

```{r}
#one-hot encode here:
library(data.table)
library(mltools)
training <- training %>%
  mutate(color.factor = as.factor(color))
training.table <- as.data.table(training)
training.table <-one_hot(training.table, cols = "color.factor")

training.color <- bind_cols(
  type = training.table$type, 
  training.table[,9:14]
)
```

```{r}
model_formula_color <- as.formula(type ~ .)
tree_parameters_color <- rpart.control(maxdepth = 5)
model_CART_color <- rpart(model_formula_color, data = training.color, control = tree_parameters_color)

# Plot CART model
plot(model_CART_color, margin=0.5)
text(model_CART_color, use.n = TRUE)
title("Predicting monster type using color as a one-hot encoded predictor")
box()
```


